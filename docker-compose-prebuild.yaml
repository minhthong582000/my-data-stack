version: '3.7'

services:
    hadoop:
        container_name: hadoop
        image: docker.pkg.github.com/minhthong582000/my-data-stack/hadoop:latest
        restart: always
        ports:
            - "8088:8088"
            - "50070:50070"
            - "50075:50075"
        volumes:
            - ./sample:/var/log/sample
            - ./configs/hosts:/etc/hosts
        networks:
            hadoop:
                ipv4_address: 172.28.1.10

    jupyterlab:
        container_name: jupyterlab
        image: docker.pkg.github.com/minhthong582000/my-data-stack/jupiterlab:latest
        ports:
            - 8888:8888
        volumes: 
            - ./scripts:/opt/workspace
        networks: 
            - hadoop
    
    spark-master:
        container_name: spark-master
        image: docker.pkg.github.com/minhthong582000/my-data-stack/spark-master:latest
        ports:
            - 8080:8080
            - 7077:7077
        networks: 
            - hadoop
    
    spark-worker-1:
        container_name: spark-worker-1
        image: docker.pkg.github.com/minhthong582000/my-data-stack/spark-worker:latest
        environment:
            - SPARK_WORKER_CORES=1
            - SPARK_WORKER_MEMORY=512m
        ports:
            - 8081:8081
        depends_on:
            - spark-master
        networks: 
            - hadoop

    db:
        image: mysql:8.0.22
        container_name: db
        command: --default-authentication-plugin=mysql_native_password
        restart: always
        network_mode: 'host'
        env_file: 
            - .env.example

# Volumes
volumes: 
    datanode:

# Network
networks:
    hadoop:
        ipam:
            driver: default
            config:
                - subnet: 172.28.0.0/16
