version: '3.7'

services:
    hadoop:
        container_name: hadoop
        # image: docker.pkg.github.com/minhthong582000/my-data-stack/hadoop:latest
        build:
            context: ./hadoop
        restart: always
        ports:
            - "8088:8088"
            - "50070:50070"
            - "50075:50075"
        volumes:
            - ./sample:/var/log/sample
            - datanode:/tmp/hadoop-root
        networks:
            hadoop:
                ipv4_address: 172.28.1.10

    jupyterlab:
        container_name: jupyterlab
        build:
            context: ./jupiter
        ports:
            - 8888:8888
        volumes:
            - shared-workspace:/opt/workspace
    
    spark-master:
        build:
            context: ./spark/master
        container_name: spark-master
        ports:
            - 8080:8080
            - 7077:7077
    
    spark-worker-1:
        build:
            context: ./spark/worker
        container_name: spark-worker-1
        environment:
            - SPARK_WORKER_CORES=1
            - SPARK_WORKER_MEMORY=512m
        ports:
            - 8081:8081
        depends_on:
            - spark-master

# Volumes
volumes: 
    datanode:

# Network
networks:
    hadoop:
        ipam:
            driver: default
            config:
                - subnet: 172.28.0.0/16
